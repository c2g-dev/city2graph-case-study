{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95fca80",
   "metadata": {},
   "source": [
    "# 02 — Graph Construction\n",
    "\n",
    "This notebook builds and saves three graph objects in `data/processed/graphs/` using processed features from `data/processed/features/`.\n",
    "\n",
    "- **2.1 Homogeneous graph (Model 1 / Baseline 2)**: queen contiguity of polygons → PyG `Data` → `homo.pt`\n",
    "- **2.2 Heterogeneous street graph (Model 2)**: contiguity + street network + 15-min street-accessibility metapaths → PyG `HeteroData` → `hetero_street.pt`\n",
    "- **2.3 Heterogeneous multi-modal graph (Model 3)**: street + bus networks; OA–OA accessibility uses minimum path cost over the combined network → PyG `HeteroData` → `hetero_multi.pt`\n",
    "\n",
    "Notes:\n",
    "- The polygon layer available in this case study is **Output Areas (OA)** (see `OA21CD`, `LSOA21CD`, `LSOA21NM`). We use OA as the spatial unit for graph nodes.\n",
    "- `pop_weighted_centroid` is stored as WKT strings in the GeoPackage and is parsed into geometry before calling `c2g.contiguity_graph()`.\n",
    "- Inter-layer connections are created using `c2g.bridge_nodes()` (proximity edges with relation name `is_nearby`).\n",
    "- Naming convention in this notebook: street nodes are `street_connector`, bus stops are `bus_station`, street edges use relation `is_connected_to`, and bus edges use relation `is_next_to`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0977e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import city2graph as c2g\n",
    "\n",
    "# Paths\n",
    "FEATURE_DIR = Path(\"../data/processed/features\")\n",
    "GRAPH_DIR = Path(\"../data/processed/graphs\")\n",
    "GRAPH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "TAU_STREET_SEC = 15 * 60  # 15 minutes\n",
    "WALKING_SPEED_MPS = 4.8 / 3.6  # 4.8 km/h in m/s\n",
    "\n",
    "# OA node feature columns (fixed list for this case study)\n",
    "OA_FEATURE_COLS = [\n",
    "    \"arts_culture\",\n",
    "    \"automotive_facility\",\n",
    "    \"consumer_service\",\n",
    "    \"corporate_service\",\n",
    "    \"education\",\n",
    "    \"entertainment\",\n",
    "    \"food_beverage\",\n",
    "    \"healthcare\",\n",
    "    \"hotel_lodging\",\n",
    "    \"industrial_service\",\n",
    "    \"park\",\n",
    "    \"public_service\",\n",
    "    \"religion\",\n",
    "    \"retail\",\n",
    "    \"sports_fitness\",\n",
    "    \"transportation_facility\",\n",
    "    \"land_use_green_space\",\n",
    "    \"land_use_residential\",\n",
    "    \"land_use_industrial\",\n",
    "    \"land_use_public_services\",\n",
    "    \"land_use_transportation\",\n",
    "    \"land_use_commercial\",\n",
    "    \"land_use_agricultural\",\n",
    "    #\"betweenness_centrality\",\n",
    "    #\"closeness_centrality\",\n",
    "    #\"degree_centrality\"\n",
    "]\n",
    "\n",
    "STREET_FEATURE_COLS = [\n",
    "    \"betweenness_centrality\",\n",
    "    \"closeness_centrality\",\n",
    "    \"degree_centrality\"\n",
    "]\n",
    "\n",
    "BUS_FEATURE_COLS = [\n",
    "    \"betweenness_centrality\",\n",
    "    \"closeness_centrality\",\n",
    "    \"degree_centrality\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OA polygons + parse pop-weighted centroids\n",
    "OA_PATH = FEATURE_DIR / \"oa_with_features.gpkg\"\n",
    "\n",
    "oa_with_features = gpd.read_file(OA_PATH)\n",
    "# Stored as WKT strings in this dataset\n",
    "oa_with_features[\"pop_weighted_centroid\"] = oa_with_features[\"pop_weighted_centroid\"].map(wkt.loads)\n",
    "\n",
    "# Use OA code as stable node identifier\n",
    "oa_with_features = oa_with_features.set_index(\"OA21CD\", drop=False)\n",
    "\n",
    "missing = [c for c in OA_FEATURE_COLS if c not in oa_with_features.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing expected OA feature columns: {missing}\")\n",
    "\n",
    "print(\"OA polygons:\", oa_with_features.shape)\n",
    "print(\"OA feature cols:\", len(OA_FEATURE_COLS))\n",
    "print(\"CRS:\", oa_with_features.crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae4432",
   "metadata": {},
   "source": [
    "## 2.0 Inspect OA Feature Distributions + Scaling\n",
    "\n",
    "The OA node features in this case study are **non-negative POI counts** per category. These typically have:\n",
    "- Many zeros (sparse),\n",
    "- Heavy right tails (a few OAs with very large counts),\n",
    "- Different scales across categories.\n",
    "\n",
    "A good default for this kind of data is:\n",
    "1. Apply $\\log(1+x)$ to compress heavy tails while keeping zeros at 0.\n",
    "2. Standardize to zero mean / unit variance so a model doesn’t over-weight high-variance categories.\n",
    "\n",
    "We compute distribution diagnostics first (zero rate, quantiles, skewness), then apply `log1p + z-score` scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ec3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Distribution diagnostics (raw) ---\n",
    "oa_feat = oa_with_features[OA_FEATURE_COLS].copy()\n",
    "oa_feat = oa_feat.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "if oa_feat.isna().any().any():\n",
    "    bad_cols = oa_feat.columns[oa_feat.isna().any()].tolist()\n",
    "    raise ValueError(f\"Found NaNs after coercing OA features to numeric: {bad_cols}\")\n",
    "\n",
    "min_val = float(oa_feat.min().min())\n",
    "if min_val < 0:\n",
    "    raise ValueError(\n",
    "        f\"Expected non-negative OA features (counts), but found min={min_val}. \"\n",
    "        \"If these aren’t counts, we should revisit the scaling choice.\"\n",
    "    )\n",
    "\n",
    "dist = pd.DataFrame(index=OA_FEATURE_COLS)\n",
    "dist[\"min\"] = oa_feat.min()\n",
    "dist[\"max\"] = oa_feat.max()\n",
    "dist[\"mean\"] = oa_feat.mean()\n",
    "dist[\"median\"] = oa_feat.median()\n",
    "dist[\"p90\"] = oa_feat.quantile(0.90)\n",
    "dist[\"p95\"] = oa_feat.quantile(0.95)\n",
    "dist[\"p99\"] = oa_feat.quantile(0.99)\n",
    "dist[\"zero_frac\"] = (oa_feat == 0).mean()\n",
    "dist[\"skew\"] = oa_feat.skew(numeric_only=True)\n",
    "\n",
    "display(dist.sort_values([\"zero_frac\", \"skew\"], ascending=False).round(3))\n",
    "\n",
    "# Quick visual: raw histograms (log y to show tails)\n",
    "_ = oa_feat.hist(bins=30, figsize=(14, 10))\n",
    "import matplotlib.pyplot as plt\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_yscale(\"log\")\n",
    "plt.suptitle(\"OA feature histograms (raw counts; log y-scale)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Apply scaling and persist back onto `oa` ---\n",
    "SCALING_METHOD = \"log1p+zscore\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on log1p-transformed counts\n",
    "X = scaler.fit_transform(np.log1p(oa_feat).to_numpy(dtype=float))\n",
    "oa_scaled_feat = pd.DataFrame(X, index=oa_with_features.index, columns=OA_FEATURE_COLS).astype(\"float32\")\n",
    "\n",
    "# Save scaling params so we can reconstruct / invert later\n",
    "scaling_info = {\n",
    "    \"method\": SCALING_METHOD,\n",
    "    \"feature_cols\": OA_FEATURE_COLS,\n",
    "    \"log1p\": True,\n",
    "    \"mean_\": scaler.mean_.tolist(),\n",
    "    \"scale_\": scaler.scale_.tolist(),\n",
    "}\n",
    "out_path = GRAPH_DIR / \"oa_feature_scaling.json\"\n",
    "out_path.write_text(json.dumps(scaling_info, indent=2))\n",
    "print(\"Saved scaling params:\", out_path)\n",
    "\n",
    "# Apply scaled features to OA GeoDataFrame (so OA node features are scaled everywhere downstream)\n",
    "oa_with_features[OA_FEATURE_COLS] = oa_scaled_feat[OA_FEATURE_COLS]\n",
    "\n",
    "# Sanity-check + histograms (scaled OA node features)\n",
    "if oa_scaled_feat.isna().any().any():\n",
    "    bad_cols = oa_scaled_feat.columns[oa_scaled_feat.isna().any()].tolist()\n",
    "    raise ValueError(f\"Found NaNs in scaled OA features: {bad_cols}\")\n",
    "\n",
    "print(\n",
    "    \"Scaled feature check: mean(abs)~\",\n",
    "    float(np.abs(oa_scaled_feat.to_numpy(dtype=float).mean(axis=0)).mean()),\n",
    "    \"std~\",\n",
    "    float(oa_scaled_feat.to_numpy(dtype=float).std(axis=0).mean()),\n",
    ")\n",
    "\n",
    "_ = oa_scaled_feat.hist(bins=30, figsize=(14, 10))\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_yscale(\"log\")\n",
    "plt.suptitle(\"OA feature histograms (scaled: log1p + z-score)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb86c8",
   "metadata": {},
   "source": [
    "##  2.1 Homogeneous graph: Queen contiguity of OA (Model 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3849a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct homogeneous graph: Queen contiguity (OA polygons)\n",
    "contig_nodes, contig_edges = c2g.contiguity_graph(\n",
    "    oa_with_features,\n",
    "    contiguity=\"queen\",\n",
    "    node_geom_col=\"pop_weighted_centroid\",\n",
    "    set_point_nodes=True,\n",
    ")\n",
    "\n",
    "# Convert to PyG Data object\n",
    "homo_data = c2g.gdf_to_pyg(\n",
    "    contig_nodes,\n",
    "    contig_edges,\n",
    "    node_feature_cols=OA_FEATURE_COLS,\n",
    ")\n",
    "\n",
    "HOMO_PATH = GRAPH_DIR / \"homo.pt\"\n",
    "torch.save(homo_data, HOMO_PATH)\n",
    "print(\"Saved:\", HOMO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf1dfa",
   "metadata": {},
   "source": [
    "## 2.2 Heterogeneous Street Graph (Model 2)\n",
    "\n",
    "We build a heterogeneous graph with node types:\n",
    "- `oa`: OA centroids (one per polygon)\n",
    "- `street_connector`: street network nodes\n",
    "\n",
    "Edge types:\n",
    "- (`oa`, `contiguity`, `oa`): queen contiguity edges from 2.1\n",
    "- (`street_connector`, `is_connected_to`, `street_connector`): street network edges weighted by `travel_time_sec`\n",
    "- (`oa`, `is_nearby`, `street_connector`): walking connectors generated via `c2g.bridge_nodes()` (KNN, k=1)\n",
    "\n",
    "We treat proximity connectors as undirected in metapath construction (`directed=False`), so we do not materialize the reverse edge type (`street_connector` → `oa`).\n",
    "\n",
    "Then we add 15-minute accessibility metapath edges between `oa` nodes using `add_metapaths_by_weight()` with `weight=\"travel_time_sec\"` and `threshold=900` seconds.\n",
    "\n",
    "This cell can take a few minutes because it runs shortest-path searches on the street network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_nodes = gpd.read_file(FEATURE_DIR / \"street_nodes.gpkg\")\n",
    "street_edges = gpd.read_file(FEATURE_DIR / \"street_edges.gpkg\")\n",
    "\n",
    "street_nodes = street_nodes.set_index(\"node_id\")\n",
    "street_edges = street_edges.set_index([\"from_node_id\", \"to_node_id\"])\n",
    "\n",
    "hetero_nodes_street = {\n",
    "    \"oa\": contig_nodes,\n",
    "    \"street_connector\": street_nodes\n",
    "}\n",
    "\n",
    "hetero_edges_street = {\n",
    "    (\"oa\", \"is_contiguous_to\", \"oa\"): contig_edges,\n",
    "    (\"street_connector\", \"is_connected_to\", \"street_connector\"): street_edges\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bridged_edges = c2g.bridge_nodes(\n",
    "    nodes_dict=hetero_nodes_street,\n",
    "    source_node_types=[\"oa\"],\n",
    "    target_node_types=[\"street_connector\"],\n",
    "    k=1\n",
    ")\n",
    "\n",
    "hetero_edges_street.update(bridged_edges)\n",
    "\n",
    "# Add travel time in seconds\n",
    "hetero_edges_street[('oa', 'is_nearby', 'street_connector')][\"travel_time_sec\"] = bridged_edges[('oa', 'is_nearby', 'street_connector')].length / WALKING_SPEED_MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add street accessibility metapaths between OA nodes (15 mins)\n",
    "hetero_nodes_street, hetero_edges_street = c2g.add_metapaths_by_weight(\n",
    "    nodes=hetero_nodes_street,\n",
    "    edges=hetero_edges_street,\n",
    "    weight=\"travel_time_sec\",\n",
    "    threshold=15 * 60.0,\n",
    "    new_relation_name=\"M_15min_walk\",\n",
    "    endpoint_type=\"oa\",\n",
    "    edge_types=[\n",
    "        (\"oa\", \"is_nearby\", \"street_connector\"),\n",
    "        (\"street_connector\", \"is_connected_to\", \"street_connector\"),\n",
    "    ],\n",
    "    directed=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ea28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2g.plot_graph(nodes=None, edges=hetero_edges_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2g.plot_graph(nodes=hetero_nodes_street[\"oa\"],\n",
    "edges=hetero_edges_street[(\"oa\", \"M_15min_walk\", \"oa\")], edge_alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab42fc",
   "metadata": {},
   "source": [
    "## 2.3 Heterogeneous Multi-modal Graph (Model 3)\n",
    "\n",
    "We extend Model 2 by adding a GTFS-derived bus network:\n",
    "- `bus_station` nodes from `travel_summary_nodes.gpkg`\n",
    "- (`bus_station`, `is_next_to`, `bus_station`) edges from `travel_summary_edges.gpkg` weighted by `travel_time_sec`\n",
    "\n",
    "We connect bus stations to the street network via nearest-neighbor walking connectors generated with `c2g.bridge_nodes()` (`bus_station` → `street_connector`, KNN k=1).\n",
    "\n",
    "In metapath construction we treat connectors as undirected (`directed=False`), so we do not materialize the reverse edge types (`street_connector` → `bus_station`, `street_connector` → `oa`).\n",
    "\n",
    "Minimum travel time $\\min(w^{street}, w^{bus})$ is achieved by running shortest-path on the *combined* network (street edges + bus edges + walking connectors); `add_metapaths_by_weight()` then creates OA–OA edges for reachable pairs within 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce209f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_summary_nodes = gpd.read_file(FEATURE_DIR / \"travel_summary_nodes.gpkg\")\n",
    "travel_summary_edges = gpd.read_file(FEATURE_DIR / \"travel_summary_edges.gpkg\")\n",
    "\n",
    "travel_summary_nodes = travel_summary_nodes.set_index(\"stop_id\")\n",
    "travel_summary_edges = travel_summary_edges.set_index([\"from_stop_id\", \"to_stop_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de12689",
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_nodes_multi = {\n",
    "    \"oa\": contig_nodes,\n",
    "    \"street_connector\": street_nodes,\n",
    "    \"bus_station\": travel_summary_nodes,\n",
    "}\n",
    "\n",
    "hetero_edges_multi = {\n",
    "    (\"oa\", \"is_contiguous_to\", \"oa\"): contig_edges,\n",
    "    (\"street_connector\", \"is_connected_to\", \"street_connector\"): street_edges,\n",
    "    (\"bus_station\", \"connects\", \"oa\"): travel_summary_edges,\n",
    "    (\"bus_station\", \"is_next_to\", \"bus_station\"): travel_summary_edges,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f99357",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bridged_edges = c2g.bridge_nodes(\n",
    "    nodes_dict=hetero_nodes_multi,\n",
    "    source_node_types=[\"oa\", \"bus_station\"],\n",
    "    target_node_types=[\"street_connector\"],\n",
    "    k=1\n",
    ")\n",
    "\n",
    "hetero_edges_multi.update(bridged_edges)\n",
    "\n",
    "# Add travel time in seconds\n",
    "hetero_edges_multi[('oa', 'is_nearby', 'street_connector')][\"travel_time_sec\"] = bridged_edges[('oa', 'is_nearby', 'street_connector')].length / WALKING_SPEED_MPS\n",
    "hetero_edges_multi[('bus_station', 'is_nearby', 'street_connector')][\"travel_time_sec\"] = bridged_edges[('bus_station', 'is_nearby', 'street_connector')].length / WALKING_SPEED_MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the baseline walking edges (from Model 2)\n",
    "# We assume hetero_edges_street exists and has populated 'M_15min_walk'.\n",
    "walking_edges = hetero_edges_street[(\"oa\", \"M_15min_walk\", \"oa\")]\n",
    "\n",
    "# 2. Compute the combined (Multi-modal) edges\n",
    "# Use a temp relation name first\n",
    "hetero_nodes_multi, hetero_edges_multi = c2g.add_metapaths_by_weight(\n",
    "    nodes=hetero_nodes_multi,\n",
    "    edges=hetero_edges_multi,\n",
    "    weight=\"travel_time_sec\",\n",
    "    threshold=15 * 60.0,\n",
    "    new_relation_name=\"M_15min_combined_raw\",\n",
    "    endpoint_type=\"oa\",\n",
    "    edge_types=[\n",
    "        (\"oa\", \"is_nearby\", \"street_connector\"),\n",
    "        (\"street_connector\", \"is_connected_to\", \"street_connector\"),\n",
    "        (\"bus_station\", \"is_nearby\", \"street_connector\"),\n",
    "        (\"bus_station\", \"is_next_to\", \"bus_station\"),\n",
    "    ],\n",
    "    directed=False\n",
    ")\n",
    "\n",
    "combined_edges = hetero_edges_multi.pop((\"oa\", \"M_15min_combined_raw\", \"oa\"))\n",
    "\n",
    "# 3. Filter: Remove edges that are in walking_edges\n",
    "# We use the index (from_node, to_node) for comparison.\n",
    "# Note: The indices might be integers or strings. We ensure alignment.\n",
    "common_index = combined_edges.index.intersection(walking_edges.index)\n",
    "transit_only_edges = combined_edges.drop(common_index)\n",
    "\n",
    "# 4. Assign to final dictionaries\n",
    "hetero_edges_multi[(\"oa\", \"M_15min_walk\", \"oa\")] = walking_edges\n",
    "hetero_edges_multi[(\"oa\", \"M_15min_multi\", \"oa\")] = transit_only_edges\n",
    "\n",
    "print(f\"Walking edges: {len(walking_edges)}\")\n",
    "print(f\"Combined edges (raw): {len(combined_edges)}\")\n",
    "print(f\"Multi-modal edges (filtered): {len(transit_only_edges)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d125465",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2g.plot_graph(nodes=hetero_nodes_multi, edges=hetero_edges_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfd86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2g.plot_graph(\n",
    "    nodes=hetero_nodes_multi[\"oa\"],\n",
    "    edges=hetero_edges_multi[(\"oa\", \"M_15min_multi\", \"oa\")],\n",
    "    edge_alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f9e50",
   "metadata": {},
   "source": [
    "### Optional: refresh saved graphs after changing scaling\n",
    "\n",
    "The metapath construction for Models 2–3 can be slow. If you only changed **OA feature scaling** (not the street/bus networks), you can rebuild and re-save the PyG graph objects using the already-computed `*_mp` dictionaries without re-running shortest paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d6bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "HETERO_STREET_PATH = GRAPH_DIR / \"hetero_street.pt\"\n",
    "HETERO_MULTI_PATH = GRAPH_DIR / \"hetero_multi.pt\"\n",
    "\n",
    "hetero_street = c2g.gdf_to_pyg(\n",
    "    hetero_nodes_street,\n",
    "    hetero_edges_street,\n",
    "    node_feature_cols={\n",
    "        \"oa\": OA_FEATURE_COLS,\n",
    "        \"street_connector\": STREET_FEATURE_COLS,\n",
    "        },\n",
    ")\n",
    "\n",
    "hetero_multi = c2g.gdf_to_pyg(\n",
    "    hetero_nodes_multi,\n",
    "    hetero_edges_multi,\n",
    "    node_feature_cols={\n",
    "        \"oa\": OA_FEATURE_COLS,\n",
    "        \"street_connector\": STREET_FEATURE_COLS,\n",
    "        \"bus_station\": BUS_FEATURE_COLS,\n",
    "    },\n",
    ")\n",
    "\n",
    "torch.save(hetero_street, HETERO_STREET_PATH)\n",
    "torch.save(hetero_multi, HETERO_MULTI_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
