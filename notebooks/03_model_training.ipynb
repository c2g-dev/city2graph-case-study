{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12129a7c",
   "metadata": {},
   "source": [
    "# 03. Model Implementation & Training\n",
    "\n",
    "This notebook covers the **Model Implementation & Training** phase (Chapter 5.3) of our case study. We aim to learn low-dimensional vector representations (embeddings) for every Output Area (OA) in Liverpool using Graph Auto-Encoders (GAE).\n",
    "\n",
    "## Objectives\n",
    "1.  **Train Graph Models**: We interpret the urban system as a graph and use GAEs to compress the structural and attribute information.\n",
    "2.  **Compare Architectures**: We evaluate different encoders:\n",
    "    *   **GAT (Homogeneous)**: Uses only spatial contiguity.\n",
    "    *   **HAN (Heterogeneous)**: Incorporates street networks and public transit (bus) to learn richer representations.\n",
    "3.  **Cluster & Visualize**: We apply K-Means to the learned embeddings to identify functional regions and visualize the results spatially and in latent space (t-SNE).\n",
    "\n",
    "## Models Overview\n",
    "*   **Baseline**: K-Means on raw features (no graph learning).\n",
    "*   **Model 1 (GAT-GAE)**: Homogeneous graph (OA contiguity).\n",
    "*   **Model 2 (HAN-GAE)**: Heterogeneous graph (OA + Street accessibility).\n",
    "*   **Model 3 (HAN-GAE)**: Heterogeneous graph (OA + Street + Bus accessibility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8304cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path to allow imports from src\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# If on Google Colab, install city2graph\n",
    "#!pip install city2graph\n",
    "\n",
    "import yaml\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import city2graph as c2g\n",
    "from torch_geometric.data import HeteroData\n",
    "from src.models import GATGAE, HANGAE\n",
    "from src.baselines.kmeans import run_kmeans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ad845",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup\n",
    "We load hyperparameters from `configs/experiment_config.yaml`. This ensures reproducibility and easy tuning of parameters like learning rate, hidden dimensions, and structure loss weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "config = load_config('../configs/experiment_config.yaml')\n",
    "\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seeds(config['seeds']['global'])\n",
    "device = torch.device(config['experiment']['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(\"../outputs/checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/embeddings\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/clusters\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7312a3a",
   "metadata": {},
   "source": [
    "## 2. Training Utility\n",
    "This general training loop handles:\n",
    "1.  **Optimization**: Updating model weights using Adam.\n",
    "2.  **Loss Calculation**: Combining Feature Reconstruction Loss (Smooth L1) and Structure Reconstruction Loss (DistMult).\n",
    "3.  **Early Stopping**: Preventing overfitting by monitoring loss improvement.\n",
    "4.  **Embedding Generation**: Extracting the latent `z` vectors from the best model state.\n",
    "5.  **Clustering**: Automatically clustering the resulting embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5455d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, config, model_name):\n",
    "    print(f\"Training {model_name}...\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['training']['lr'], weight_decay=config['training']['weight_decay'])\n",
    "    best_loss = float('inf')\n",
    "    patience = config['training']['early_stopping_patience']\n",
    "    patience_counter = 0\n",
    "    \n",
    "    checkpoint_dir = f\"../outputs/checkpoints/{model_name}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(config['training']['epochs']):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss, l_feat, l_struct = model.compute_loss(\n",
    "            data, \n",
    "            lambda_struct=config['model']['lambda_struct'],\n",
    "            neg_sampling_scale=config['training'][\"negative_sampling_scale\"]\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Logging\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Total Loss: {loss.item():.4f}, Feat Loss: {l_feat.item():.4f}, Struct Loss: {l_struct.item():.4f}\")\n",
    "            \n",
    "        # Early Stopping\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), f\"{checkpoint_dir}/model.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "            \n",
    "    # Load best model for embedding generation\n",
    "    model.load_state_dict(torch.load(f\"{checkpoint_dir}/model.pt\"))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(model, GATGAE):\n",
    "            z, _ = model(data)\n",
    "        else: # HANGAE\n",
    "            z, _, beta = model(data)\n",
    "        \n",
    "        # Save embeddings\n",
    "        torch.save(z, f\"../outputs/embeddings/{model_name}.pt\")\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ace6da",
   "metadata": {},
   "source": [
    "## 3. Visualization Utilities\n",
    "To interpret the results, we use three key visualizations:\n",
    "1.  **Training Curve**: Ensures the model is learning (loss should decrease).\n",
    "2.  **Spatial Map**: Plots the OAs color-coded by cluster assignment to reveal geographic patterns. Uses `city2graph` plotting utility.\n",
    "3.  **t-SNE Plot**: Projects the high-dimensional embeddings to 2D using t-SNE to visualize the manifold structure and cluster separability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "oa = gpd.read_file(\"../data/processed/features/oa_with_features.gpkg\")\n",
    "\n",
    "oa = oa[[\"OA21CD\", \"geometry\"]].set_index(\"OA21CD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf194926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_best_cluster_number(z, min_k=1, max_k=15, algorithm=KMeans, seed=config['seeds']['clustering'], **kwargs):\n",
    "    \"\"\"Determines optimal cluster number using Silhouette Score.\"\"\"\n",
    "    print(f\"Determining optimal clusters using {algorithm.__name__}...\")\n",
    "    best_score = -1\n",
    "    best_k = min_k\n",
    "    \n",
    "    X_np = z.cpu().numpy() if isinstance(z, torch.Tensor) else z\n",
    "    \n",
    "    for k in range(min_k, max_k + 1):\n",
    "        model = algorithm(n_clusters=k, random_state=seed, **kwargs)\n",
    "        lbls = model.fit_predict(X_np)\n",
    "        if len(set(lbls)) < 2:\n",
    "             continue\n",
    "        score = silhouette_score(X_np, lbls)\n",
    "        # print(f\"k={k}, score={score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            \n",
    "    print(f\"Optimal k={best_k} (Score: {best_score:.4f})\")\n",
    "    return best_k\n",
    "\n",
    "def perform_clustering(z, n_clusters, algorithm=KMeans, output_file=None, seed=config['seeds']['clustering'], **kwargs):\n",
    "    \"\"\"Runs clustering and optionally saves to CSV.\"\"\"\n",
    "    X_np = z.cpu().numpy() if isinstance(z, torch.Tensor) else z\n",
    "    model = algorithm(n_clusters=n_clusters, random_state=seed, **kwargs)\n",
    "    labels = model.fit_predict(X_np)\n",
    "    \n",
    "    if output_file:\n",
    "        df = pd.DataFrame({'cluster': labels})\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Clusters saved to {output_file}\")\n",
    "        \n",
    "    return labels\n",
    "\n",
    "def plot_training_curve(losses, model_name):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, label='Total Loss')\n",
    "    plt.title(f\"{model_name} Training Convergence\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"../outputs/figures/{model_name}_loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_clusters_spatial(data, cluster_labels=None, cluster_file=None, model_name=\"Model\"):\n",
    "    \"\"\"Plots clusters using standard GeoPandas plot (Choropleth). Accepts either labels or a file.\"\"\"\n",
    "    print(f\"\\n--- Plotting Clusters for {model_name} ---\")\n",
    "    \n",
    "    # Load Reference Geometry (OA)\n",
    "    oa_path = \"../data/processed/features/oa_with_features.gpkg\"\n",
    "    if not os.path.exists(oa_path):\n",
    "        print(f\"Geometry file not found at {oa_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load only geometry and ID to be safe\n",
    "    oa_geom = gpd.read_file(oa_path)[[\"OA21CD\", \"geometry\"]].set_index(\"OA21CD\")\n",
    "\n",
    "    if cluster_labels is None:\n",
    "        if cluster_file and os.path.exists(cluster_file):\n",
    "            clusters_df = pd.read_csv(cluster_file)\n",
    "            cluster_labels = clusters_df['cluster'].values\n",
    "            print(f\"Loaded clusters from {cluster_file}: {len(cluster_labels)} rows\")\n",
    "        else:\n",
    "            print(\"No cluster labels or valid file provided.\")\n",
    "            return\n",
    "\n",
    "    # Recover PyG Data to get Node IDs / Index\n",
    "    if isinstance(data, HeteroData):\n",
    "        data.graph_metadata.edge_types = list(data.edge_types)\n",
    "        nodes_dict, _ = c2g.pyg_to_gdf(data)\n",
    "        gdf_nodes = nodes_dict['oa']\n",
    "    else:\n",
    "        gdf_nodes, _ = c2g.pyg_to_gdf(data)\n",
    "        \n",
    "    # Assign clusters to the inferred node order\n",
    "    if len(cluster_labels) != len(gdf_nodes):\n",
    "         print(f\"Warning: Length mismatch. Nodes: {len(gdf_nodes)}, Clusters: {len(cluster_labels)}\")\n",
    "         return\n",
    "\n",
    "    gdf_nodes['cluster'] = cluster_labels\n",
    "    \n",
    "    # Merge with geometry\n",
    "    gdf_nodes = gdf_nodes.drop(columns=['geometry']).join(oa_geom, how='inner', rsuffix='_oa')\n",
    "    print(f\"Merged for Plotting: {len(gdf_nodes)} rows\")\n",
    "    \n",
    "    # Normalize geometry column\n",
    "    gdf_nodes = gdf_nodes.rename(columns={'geometry_oa': 'geometry'}).set_geometry('geometry')\n",
    "    \n",
    "    # PLOT using GeoPandas with enhanced aesthetics\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), dpi=150)\n",
    "    \n",
    "    gdf_nodes.plot(\n",
    "        column='cluster', \n",
    "        categorical=True,\n",
    "        cmap='tab20', \n",
    "        legend=True, \n",
    "        legend_kwds={'loc': 'center left', 'bbox_to_anchor': (1, 0.5), 'title': 'Cluster ID', 'frameon': False},\n",
    "        ax=ax,\n",
    "        edgecolor='white',\n",
    "        linewidth=0.05\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"{model_name} Spatial Clusters\", fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    output_fig = f\"../outputs/figures/{model_name}_spatial.png\"\n",
    "    plt.savefig(output_fig, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Plot saved to {output_fig}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_embeddings_tsne(embedding_file, cluster_file=None, cluster_labels=None, model_name=\"Model\", seed=config['seeds']['tsne']):\n",
    "    \"\"\"Plots t-SNE of the embeddings colored by cluster.\"\"\"\n",
    "    if not os.path.exists(embedding_file):\n",
    "        print(f\"Missing embedding file: {embedding_file}\")\n",
    "        return\n",
    "        \n",
    "    z = torch.load(embedding_file, map_location=torch.device('cpu'), weights_only=False)\n",
    "    if isinstance(z, torch.Tensor):\n",
    "        z = z.cpu().numpy()\n",
    "        \n",
    "    if cluster_labels is None:\n",
    "         if cluster_file and os.path.exists(cluster_file):\n",
    "             cluster_labels = pd.read_csv(cluster_file)['cluster'].values\n",
    "         else:\n",
    "             print(\"No cluster labels provided for t-SNE.\")\n",
    "             return\n",
    "    \n",
    "    print(\"Running t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, max_iter=1000, random_state=seed)\n",
    "    z_tsne = tsne.fit_transform(z)\n",
    "    \n",
    "    # Plotting with enhanced aesthetics\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), dpi=150)\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        z_tsne[:, 0], \n",
    "        z_tsne[:, 1], \n",
    "        c=cluster_labels, \n",
    "        cmap='tab20', \n",
    "        s=15, \n",
    "        alpha=0.7,\n",
    "        edgecolor='none'\n",
    "    )\n",
    "    \n",
    "    # Create a legend for clusters\n",
    "    legend1 = ax.legend(*scatter.legend_elements(), title=\"Cluster\", loc=\"upper right\", bbox_to_anchor=(1.15, 1), frameon=False)\n",
    "    ax.add_artist(legend1)\n",
    "    \n",
    "    ax.set_title(f\"{model_name} Embeddings (t-SNE)\", fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Dimension 1\", fontsize=10)\n",
    "    ax.set_ylabel(\"Dimension 2\", fontsize=10)\n",
    "    \n",
    "    # Remove top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113cc153",
   "metadata": {},
   "source": [
    "## 4. Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd89b8",
   "metadata": {},
   "source": [
    "### 4.1. Baseline: K-Means on Raw Features\n",
    "This establishes a benchmark. We cluster OAs based purely on their feature vectors (POI counts vs Land Use) without any relationship information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Baseline 1: K-Means on Raw Features...\")\n",
    "homo_path = os.path.join(\"../\", config['data']['root'], config['data']['homo'])\n",
    "\n",
    "homo_data = torch.load(homo_path, map_location=device, weights_only=False)\n",
    "\n",
    "# Baseline Clustering\n",
    "baseline_k = identify_best_cluster_number(homo_data.x, algorithm=KMeans)\n",
    "baseline_labels = perform_clustering(homo_data.x, baseline_k, algorithm=KMeans, output_file='../outputs/clusters/baseline1_kmeans.csv')\n",
    "print(\"Baseline clustering completed.\")\n",
    "\n",
    "# Visualizations\n",
    "plot_clusters_spatial(homo_data, cluster_labels=baseline_labels, model_name='Baseline (K-Means)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f437ba",
   "metadata": {},
   "source": [
    "### 4.2. Model 1: GAT-GAE (Homogeneous)\n",
    "This model learns embeddings by aggregating features from spatially contiguous neighbors. It assumes that functional regions are spatially smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e187e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(config['seeds']['model']) # Ensure deterministic model training initialization\n",
    "homo_data = homo_data.to(device)\n",
    "gat_model = GATGAE(\n",
    "    in_dim=config['model']['in_dim'],\n",
    "    hidden_dim=config['model']['hidden_dim'],\n",
    "    out_dim=config['model']['out_dim'],\n",
    "    heads=config['model']['heads'],\n",
    "    dropout=config['model']['dropout']\n",
    ").to(device)\n",
    "\n",
    "losses_model1 = train_model(gat_model, homo_data, config, \"model1_gat_gae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0fb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embeddings\n",
    "z1 = torch.load('../outputs/embeddings/model1_gat_gae.pt', weights_only=False)\n",
    "\n",
    "#z1 = F.normalize(z1, p=2, dim=-1)\n",
    "\n",
    "# Clustering Workflow\n",
    "best_k1 = identify_best_cluster_number(z1, algorithm=KMeans)\n",
    "labels1 = perform_clustering(z1, best_k1, algorithm=KMeans, output_file='../outputs/clusters/model1_gat_gae.csv')\n",
    "\n",
    "# Visualizations\n",
    "plot_training_curve(losses_model1, \"Model 1\")\n",
    "plot_clusters_spatial(homo_data, cluster_labels=labels1, model_name='Model 1 (GAT-GAE)')\n",
    "plot_embeddings_tsne('../outputs/embeddings/model1_gat_gae.pt', cluster_labels=labels1, model_name='Model 1 (GAT-GAE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a98081",
   "metadata": {},
   "source": [
    "### 4.3. Model 2: HAN-GAE (Street)\n",
    "This model introduces heterogeneity. It learns to aggregate information not just from contiguous OAs, but also from OAs connected via the street network (15-min walk). This captures functional connectivity that might skip boundaries (e.g., across a park or river connected by a bridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79804667",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(config['seeds']['model']) # Ensure deterministic model training initialization\n",
    "print(\"\\nRunning Model 2: HAN-GAE (Street)...\")\n",
    "street_path = os.path.join(\"../\", config['data']['root'], config['data']['hetero_street'])\n",
    "\n",
    "street_data = torch.load(street_path, map_location=device, weights_only=False)\n",
    "\n",
    "# Define metapaths for Model 2\n",
    "metapaths_street = ['is_contiguous_to', 'M_15min_walk']\n",
    "\n",
    "han_street = HANGAE(\n",
    "    in_dim=config['model']['in_dim'],\n",
    "    hidden_dim=config['model']['hidden_dim'],\n",
    "    out_dim=config['model']['out_dim'],\n",
    "    metapaths=metapaths_street,\n",
    "    heads=config['model']['heads'],\n",
    "    dropout=config['model']['dropout']\n",
    ").to(device)\n",
    "\n",
    "losses_model2 = train_model(han_street, street_data, config, \"model2_han_gae_street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embeddings\n",
    "z2 = torch.load('../outputs/embeddings/model2_han_gae_street.pt', weights_only=False)\n",
    "\n",
    "#z2 = F.normalize(z2, p=2, dim=-1)\n",
    "\n",
    "# Clustering Workflow\n",
    "best_k2 = identify_best_cluster_number(z2, algorithm=KMeans)\n",
    "labels2 = perform_clustering(z2, best_k2, algorithm=KMeans, output_file='../outputs/clusters/model2_han_gae_street.csv')\n",
    "\n",
    "# Visualizations\n",
    "plot_training_curve(losses_model2, \"Model 2\")\n",
    "plot_clusters_spatial(street_data, cluster_labels=labels2, model_name='Model 2 (Street)')\n",
    "plot_embeddings_tsne('../outputs/embeddings/model2_han_gae_street.pt', cluster_labels=labels2, model_name='Model 2 (Street)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e835e",
   "metadata": {},
   "source": [
    "### 4.4. Model 3: HAN-GAE (Multi-modal)\n",
    "This is the most advanced model. It incorporates public transit (Bus) edges into the accessibility layer. OAs are connected if reachable within 15 minutes by *walking OR bus*. This is expected to cluster disjoint areas that are functionally linked by rapid transit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(config['seeds']['model']) # Ensure deterministic model training initialization\n",
    "print(\"\\nRunning Model 3: HAN-GAE (Multi-modal)...\")\n",
    "multi_path = os.path.join(\"../\", config['data']['root'], config['data']['hetero_multi'])\n",
    "\n",
    "multi_data = torch.load(multi_path, map_location=device, weights_only=False)\n",
    "\n",
    "# Metapaths for Model 3\n",
    "metapaths_multi = ['is_contiguous_to', 'M_15min_walk', 'M_15min_multi']\n",
    "\n",
    "han_multi = HANGAE(\n",
    "    in_dim=config['model']['in_dim'],\n",
    "    hidden_dim=config['model']['hidden_dim'],\n",
    "    out_dim=config['model']['out_dim'],\n",
    "    metapaths=metapaths_multi,\n",
    "    heads=config['model']['heads'],\n",
    "    dropout=config['model']['dropout']\n",
    ").to(device)\n",
    "\n",
    "losses_model3 = train_model(han_multi, multi_data, config, \"model3_han_gae_multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embeddings\n",
    "z3 = torch.load('../outputs/embeddings/model3_han_gae_multi.pt', weights_only=False)\n",
    "\n",
    "#z3 = F.normalize(z3, p=2, dim=-1)\n",
    " \n",
    "# Clustering Workflow\n",
    "best_k3 = identify_best_cluster_number(z3, algorithm=KMeans)\n",
    "labels3 = perform_clustering(z3, 5, algorithm=KMeans, output_file='../outputs/clusters/model3_han_gae_multi.csv')\n",
    "\n",
    "# Visualizations\n",
    "plot_training_curve(losses_model3, \"Model 3\")\n",
    "plot_clusters_spatial(multi_data, cluster_labels=labels3, model_name='Model 3 (Multi)')\n",
    "plot_embeddings_tsne('../outputs/embeddings/model3_han_gae_multi.pt', cluster_labels=labels3, model_name='Model 3 (Multi)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
